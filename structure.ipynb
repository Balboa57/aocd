{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Assignment_data.csv\")\n",
    "\n",
    "# Convert Unix Epoch Time to standard datetime\n",
    "data['time'] = pd.to_datetime(data['time'], unit='s')\n",
    "\n",
    "# Sort data by device and time\n",
    "data = data.sort_values(by=['device', 'time'])\n",
    "\n",
    "# Create a session identifier by grouping consecutive gameplays\n",
    "data['session_id'] = (data['device'] != data['device'].shift()) | (data['time'].diff() > pd.Timedelta(hours=1))\n",
    "data['session_id'] = data['session_id'].cumsum()\n",
    "\n",
    "# Calculate Average Score per Session\n",
    "session_scores = data.groupby(['device', 'session_id'])['score'].sum().reset_index()\n",
    "avg_score_per_session = session_scores.groupby('device')['score'].mean().rename('avg_score_per_session')\n",
    "\n",
    "# Calculate Total Sessions per Player\n",
    "total_sessions = session_scores.groupby('device').size().rename('total_sessions')\n",
    "\n",
    "# Calculate Session Frequency (average time between sessions)\n",
    "session_times = data.groupby(['device', 'session_id'])['time'].max().reset_index()\n",
    "session_times['time_diff'] = session_times.groupby('device')['time'].diff().dt.total_seconds()\n",
    "session_frequency = session_times.groupby('device')['time_diff'].mean().rename('session_frequency')\n",
    "\n",
    "# Calculate Max Score in a Session\n",
    "max_score_per_session = session_scores.groupby('device')['score'].max().rename('max_score_per_session')\n",
    "\n",
    "# Calculate Recency of Last Session\n",
    "last_session_time = session_times.groupby('device')['time'].max()\n",
    "data_end_time = data['time'].max()\n",
    "recency_of_last_session = (data_end_time - last_session_time).dt.days.rename('recency_of_last_session')\n",
    "\n",
    "# Combine all new features into a single dataframe\n",
    "new_features = pd.concat([\n",
    "    avg_score_per_session,\n",
    "    total_sessions,\n",
    "    session_frequency,\n",
    "    max_score_per_session,\n",
    "    recency_of_last_session\n",
    "], axis=1).reset_index()\n",
    "\n",
    "# Merge new features back into the original data\n",
    "data = data.merge(new_features, on='device', how='left')\n",
    "\n",
    "# Drop intermediate columns that are no longer needed\n",
    "data = data.drop(columns=['session_id'], errors='ignore')\n",
    "\n",
    "# Create the churn feature\n",
    "churn_period = pd.Timedelta(days=14)\n",
    "data['last_activity'] = data.groupby('device')['time'].transform('max')\n",
    "data['churn'] = (data['last_activity'] + churn_period < data['time'].max()).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>avg_score_per_session</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>session_frequency</th>\n",
       "      <th>max_score_per_session</th>\n",
       "      <th>recency_of_last_session</th>\n",
       "      <th>last_activity</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>2015-04-11 11:52:38</td>\n",
       "      <td>205.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.642411e+07</td>\n",
       "      <td>237.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2016-02-11 07:56:21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>2015-04-11 11:53:33</td>\n",
       "      <td>205.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.642411e+07</td>\n",
       "      <td>237.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2016-02-11 07:56:21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2015-04-11 11:54:32</td>\n",
       "      <td>205.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.642411e+07</td>\n",
       "      <td>237.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2016-02-11 07:56:21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "      <td>2016-02-11 07:56:21</td>\n",
       "      <td>205.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.642411e+07</td>\n",
       "      <td>237.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2016-02-11 07:56:21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000000000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-23 02:04:44</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.558758e+06</td>\n",
       "      <td>5847.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2016-01-27 10:20:57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153924</th>\n",
       "      <td>NaN</td>\n",
       "      <td>847</td>\n",
       "      <td>2015-01-21 14:14:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153925</th>\n",
       "      <td>NaN</td>\n",
       "      <td>374</td>\n",
       "      <td>2015-01-21 14:15:37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153926</th>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>2015-01-21 14:16:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153927</th>\n",
       "      <td>NaN</td>\n",
       "      <td>112</td>\n",
       "      <td>2015-01-21 14:16:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153928</th>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>2015-01-21 14:17:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153929 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 device  score                time  avg_score_per_session  \\\n",
       "0                     0     45 2015-04-11 11:52:38                  205.5   \n",
       "1                     0    115 2015-04-11 11:53:33                  205.5   \n",
       "2                     0     14 2015-04-11 11:54:32                  205.5   \n",
       "3                     0    237 2016-02-11 07:56:21                  205.5   \n",
       "4       000000000000000      1 2015-01-23 02:04:44                 1518.0   \n",
       "...                 ...    ...                 ...                    ...   \n",
       "153924              NaN    847 2015-01-21 14:14:14                    NaN   \n",
       "153925              NaN    374 2015-01-21 14:15:37                    NaN   \n",
       "153926              NaN     35 2015-01-21 14:16:05                    NaN   \n",
       "153927              NaN    112 2015-01-21 14:16:52                    NaN   \n",
       "153928              NaN     31 2015-01-21 14:17:18                    NaN   \n",
       "\n",
       "        total_sessions  session_frequency  max_score_per_session  \\\n",
       "0                  2.0       2.642411e+07                  237.0   \n",
       "1                  2.0       2.642411e+07                  237.0   \n",
       "2                  2.0       2.642411e+07                  237.0   \n",
       "3                  2.0       2.642411e+07                  237.0   \n",
       "4                  8.0       4.558758e+06                 5847.0   \n",
       "...                ...                ...                    ...   \n",
       "153924             NaN                NaN                    NaN   \n",
       "153925             NaN                NaN                    NaN   \n",
       "153926             NaN                NaN                    NaN   \n",
       "153927             NaN                NaN                    NaN   \n",
       "153928             NaN                NaN                    NaN   \n",
       "\n",
       "        recency_of_last_session       last_activity  churn  \n",
       "0                         103.0 2016-02-11 07:56:21      1  \n",
       "1                         103.0 2016-02-11 07:56:21      1  \n",
       "2                         103.0 2016-02-11 07:56:21      1  \n",
       "3                         103.0 2016-02-11 07:56:21      1  \n",
       "4                         118.0 2016-01-27 10:20:57      1  \n",
       "...                         ...                 ...    ...  \n",
       "153924                      NaN                 NaT      0  \n",
       "153925                      NaN                 NaT      0  \n",
       "153926                      NaN                 NaT      0  \n",
       "153927                      NaN                 NaT      0  \n",
       "153928                      NaN                 NaT      0  \n",
       "\n",
       "[153929 rows x 10 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate additional features\n",
    "# 1. Total Score per Player\n",
    "data['total_score'] = data.groupby('device')['score'].transform('sum')\n",
    "\n",
    "# 2. Average Score per Session\n",
    "data['avg_score'] = data.groupby('device')['score'].transform('mean')\n",
    "\n",
    "# 3. Max Score in a Single Session\n",
    "data['max_score'] = data.groupby('device')['score'].transform('max')\n",
    "\n",
    "# 4. Standard Deviation of Scores\n",
    "data['std_score'] = data.groupby('device')['score'].transform('std').fillna(0)  # Replace NaN with 0 for single-session players\n",
    "\n",
    "# 5. Days Since First Activity\n",
    "data['days_since_first'] = (data['time'] - data.groupby('device')['time'].transform('min')).dt.days\n",
    "\n",
    "# 6. Days Between Sessions\n",
    "data['days_between_sessions'] = data.groupby('device')['time'].diff().dt.days.fillna(0)  # Fill NaN for first session\n",
    "\n",
    "# 7. Session Count\n",
    "data['session_count'] = data.groupby('device')['time'].transform('count')\n",
    "\n",
    "# 8. Score Density (Score per Day)\n",
    "data['score_density'] = data['total_score'] / (data['days_since_first'] + 1)  # Avoid division by zero\n",
    "\n",
    "# 9. Last Session Score Ratio\n",
    "data['last_session_score'] = data.groupby('device')['score'].transform('last')\n",
    "data['last_score_ratio'] = data['last_session_score'] / (data['avg_score'] + 1)  # Avoid division by zero\n",
    "\n",
    "# 10. Activity Intensity (Sessions per Day)\n",
    "data['activity_intensity'] = data['session_count'] / (data['days_since_first'] + 1)  # Avoid division by zero\n",
    "\n",
    "data['combined_score'] = data['total_score'] / data['session_count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>avg_score_per_session</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>session_frequency</th>\n",
       "      <th>max_score_per_session</th>\n",
       "      <th>recency_of_last_session</th>\n",
       "      <th>last_activity</th>\n",
       "      <th>churn</th>\n",
       "      <th>...</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>days_since_first</th>\n",
       "      <th>days_between_sessions</th>\n",
       "      <th>session_count</th>\n",
       "      <th>score_density</th>\n",
       "      <th>last_session_score</th>\n",
       "      <th>last_score_ratio</th>\n",
       "      <th>activity_intensity</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>2015-04-11 11:52:38</td>\n",
       "      <td>205.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.642411e+07</td>\n",
       "      <td>237.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2016-02-11 07:56:21</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>237.0</td>\n",
       "      <td>98.969271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>237.0</td>\n",
       "      <td>2.284337</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>102.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>2015-04-11 11:53:33</td>\n",
       "      <td>205.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.642411e+07</td>\n",
       "      <td>237.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2016-02-11 07:56:21</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>237.0</td>\n",
       "      <td>98.969271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>237.0</td>\n",
       "      <td>2.284337</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>102.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2015-04-11 11:54:32</td>\n",
       "      <td>205.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.642411e+07</td>\n",
       "      <td>237.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2016-02-11 07:56:21</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>237.0</td>\n",
       "      <td>98.969271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>237.0</td>\n",
       "      <td>2.284337</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>102.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "      <td>2016-02-11 07:56:21</td>\n",
       "      <td>205.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.642411e+07</td>\n",
       "      <td>237.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2016-02-11 07:56:21</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>237.0</td>\n",
       "      <td>98.969271</td>\n",
       "      <td>305.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.343137</td>\n",
       "      <td>237.0</td>\n",
       "      <td>2.284337</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>102.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000000000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-23 02:04:44</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.558758e+06</td>\n",
       "      <td>5847.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2016-01-27 10:20:57</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2317.0</td>\n",
       "      <td>398.282132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>12144.000000</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.377544</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>303.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153924</th>\n",
       "      <td>NaN</td>\n",
       "      <td>847</td>\n",
       "      <td>2015-01-21 14:14:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153925</th>\n",
       "      <td>NaN</td>\n",
       "      <td>374</td>\n",
       "      <td>2015-01-21 14:15:37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153926</th>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>2015-01-21 14:16:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153927</th>\n",
       "      <td>NaN</td>\n",
       "      <td>112</td>\n",
       "      <td>2015-01-21 14:16:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153928</th>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>2015-01-21 14:17:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153929 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 device  score                time  avg_score_per_session  \\\n",
       "0                     0     45 2015-04-11 11:52:38                  205.5   \n",
       "1                     0    115 2015-04-11 11:53:33                  205.5   \n",
       "2                     0     14 2015-04-11 11:54:32                  205.5   \n",
       "3                     0    237 2016-02-11 07:56:21                  205.5   \n",
       "4       000000000000000      1 2015-01-23 02:04:44                 1518.0   \n",
       "...                 ...    ...                 ...                    ...   \n",
       "153924              NaN    847 2015-01-21 14:14:14                    NaN   \n",
       "153925              NaN    374 2015-01-21 14:15:37                    NaN   \n",
       "153926              NaN     35 2015-01-21 14:16:05                    NaN   \n",
       "153927              NaN    112 2015-01-21 14:16:52                    NaN   \n",
       "153928              NaN     31 2015-01-21 14:17:18                    NaN   \n",
       "\n",
       "        total_sessions  session_frequency  max_score_per_session  \\\n",
       "0                  2.0       2.642411e+07                  237.0   \n",
       "1                  2.0       2.642411e+07                  237.0   \n",
       "2                  2.0       2.642411e+07                  237.0   \n",
       "3                  2.0       2.642411e+07                  237.0   \n",
       "4                  8.0       4.558758e+06                 5847.0   \n",
       "...                ...                ...                    ...   \n",
       "153924             NaN                NaN                    NaN   \n",
       "153925             NaN                NaN                    NaN   \n",
       "153926             NaN                NaN                    NaN   \n",
       "153927             NaN                NaN                    NaN   \n",
       "153928             NaN                NaN                    NaN   \n",
       "\n",
       "        recency_of_last_session       last_activity  churn  ...  max_score  \\\n",
       "0                         103.0 2016-02-11 07:56:21      1  ...      237.0   \n",
       "1                         103.0 2016-02-11 07:56:21      1  ...      237.0   \n",
       "2                         103.0 2016-02-11 07:56:21      1  ...      237.0   \n",
       "3                         103.0 2016-02-11 07:56:21      1  ...      237.0   \n",
       "4                         118.0 2016-01-27 10:20:57      1  ...     2317.0   \n",
       "...                         ...                 ...    ...  ...        ...   \n",
       "153924                      NaN                 NaT      0  ...        NaN   \n",
       "153925                      NaN                 NaT      0  ...        NaN   \n",
       "153926                      NaN                 NaT      0  ...        NaN   \n",
       "153927                      NaN                 NaT      0  ...        NaN   \n",
       "153928                      NaN                 NaT      0  ...        NaN   \n",
       "\n",
       "         std_score  days_since_first  days_between_sessions  session_count  \\\n",
       "0        98.969271               0.0                    0.0            4.0   \n",
       "1        98.969271               0.0                    0.0            4.0   \n",
       "2        98.969271               0.0                    0.0            4.0   \n",
       "3        98.969271             305.0                  305.0            4.0   \n",
       "4       398.282132               0.0                    0.0           40.0   \n",
       "...            ...               ...                    ...            ...   \n",
       "153924    0.000000               NaN                    0.0            NaN   \n",
       "153925    0.000000               NaN                    0.0            NaN   \n",
       "153926    0.000000               NaN                    0.0            NaN   \n",
       "153927    0.000000               NaN                    0.0            NaN   \n",
       "153928    0.000000               NaN                    0.0            NaN   \n",
       "\n",
       "        score_density  last_session_score  last_score_ratio  \\\n",
       "0          411.000000               237.0          2.284337   \n",
       "1          411.000000               237.0          2.284337   \n",
       "2          411.000000               237.0          2.284337   \n",
       "3            1.343137               237.0          2.284337   \n",
       "4        12144.000000               115.0          0.377544   \n",
       "...               ...                 ...               ...   \n",
       "153924            NaN                 NaN               NaN   \n",
       "153925            NaN                 NaN               NaN   \n",
       "153926            NaN                 NaN               NaN   \n",
       "153927            NaN                 NaN               NaN   \n",
       "153928            NaN                 NaN               NaN   \n",
       "\n",
       "        activity_intensity  combined_score  \n",
       "0                 4.000000          102.75  \n",
       "1                 4.000000          102.75  \n",
       "2                 4.000000          102.75  \n",
       "3                 0.013072          102.75  \n",
       "4                40.000000          303.60  \n",
       "...                    ...             ...  \n",
       "153924                 NaN             NaN  \n",
       "153925                 NaN             NaN  \n",
       "153926                 NaN             NaN  \n",
       "153927                 NaN             NaN  \n",
       "153928                 NaN             NaN  \n",
       "\n",
       "[153929 rows x 22 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before imputation:\n",
      "avg_score_per_session          9\n",
      "total_sessions                 9\n",
      "session_frequency          39425\n",
      "max_score_per_session          9\n",
      "recency_of_last_session        9\n",
      "total_score                    9\n",
      "avg_score                      9\n",
      "max_score                      9\n",
      "std_score                      0\n",
      "days_since_first               9\n",
      "days_between_sessions          0\n",
      "session_count                  9\n",
      "score_density                  9\n",
      "last_score_ratio               9\n",
      "activity_intensity             9\n",
      "last_session_score             9\n",
      "combined_score                 9\n",
      "dtype: int64\n",
      "\n",
      "Missing values after imputation:\n",
      "avg_score_per_session      0\n",
      "total_sessions             0\n",
      "session_frequency          0\n",
      "max_score_per_session      0\n",
      "recency_of_last_session    0\n",
      "total_score                0\n",
      "avg_score                  0\n",
      "max_score                  0\n",
      "std_score                  0\n",
      "days_since_first           0\n",
      "days_between_sessions      0\n",
      "session_count              0\n",
      "score_density              0\n",
      "last_score_ratio           0\n",
      "activity_intensity         0\n",
      "last_session_score         0\n",
      "combined_score             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define columns to check for missing values\n",
    "columns_to_impute = [\n",
    "    'avg_score_per_session', 'total_sessions', 'session_frequency',\n",
    "    'max_score_per_session', 'recency_of_last_session',\n",
    "    'total_score', 'avg_score', 'max_score', 'std_score',\n",
    "    'days_since_first', 'days_between_sessions', 'session_count',\n",
    "    'score_density', 'last_score_ratio', 'activity_intensity', 'last_session_score',\n",
    "    'combined_score'\n",
    "]\n",
    "\n",
    "# Filter out non-numeric columns\n",
    "columns_to_impute = [col for col in columns_to_impute if pd.api.types.is_numeric_dtype(data[col])]\n",
    "\n",
    "# Check missing values before imputation\n",
    "print(\"Missing values before imputation:\")\n",
    "print(data[columns_to_impute].isnull().sum())\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data[columns_to_impute] = imputer.fit_transform(data[columns_to_impute])\n",
    "\n",
    "# Check missing values after imputation\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(data[columns_to_impute].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>avg_score_per_session</th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>session_frequency</th>\n",
       "      <th>max_score_per_session</th>\n",
       "      <th>recency_of_last_session</th>\n",
       "      <th>last_activity</th>\n",
       "      <th>churn</th>\n",
       "      <th>...</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>days_since_first</th>\n",
       "      <th>days_between_sessions</th>\n",
       "      <th>session_count</th>\n",
       "      <th>score_density</th>\n",
       "      <th>last_session_score</th>\n",
       "      <th>last_score_ratio</th>\n",
       "      <th>activity_intensity</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>2015-04-11 11:52:38</td>\n",
       "      <td>205.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.642411e+07</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2016-02-11 07:56:21</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>98.969271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>2.284337</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>102.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>2015-04-11 11:53:33</td>\n",
       "      <td>205.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.642411e+07</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2016-02-11 07:56:21</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>98.969271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>2.284337</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>102.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2015-04-11 11:54:32</td>\n",
       "      <td>205.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.642411e+07</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2016-02-11 07:56:21</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>98.969271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>2.284337</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>102.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "      <td>2016-02-11 07:56:21</td>\n",
       "      <td>205.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.642411e+07</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2016-02-11 07:56:21</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>98.969271</td>\n",
       "      <td>305.000000</td>\n",
       "      <td>305.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.343137</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>2.284337</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>102.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000000000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-23 02:04:44</td>\n",
       "      <td>1518.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.558758e+06</td>\n",
       "      <td>5847.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>2016-01-27 10:20:57</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2317.000000</td>\n",
       "      <td>398.282132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>12144.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.377544</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>303.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153924</th>\n",
       "      <td>NaN</td>\n",
       "      <td>847</td>\n",
       "      <td>2015-01-21 14:14:14</td>\n",
       "      <td>928.088027</td>\n",
       "      <td>19.677228</td>\n",
       "      <td>7.685628e+05</td>\n",
       "      <td>2988.706919</td>\n",
       "      <td>265.785843</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>889.185616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.112916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.465683</td>\n",
       "      <td>5143.795710</td>\n",
       "      <td>227.713325</td>\n",
       "      <td>1.136714</td>\n",
       "      <td>29.875625</td>\n",
       "      <td>195.927034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153925</th>\n",
       "      <td>NaN</td>\n",
       "      <td>374</td>\n",
       "      <td>2015-01-21 14:15:37</td>\n",
       "      <td>928.088027</td>\n",
       "      <td>19.677228</td>\n",
       "      <td>7.685628e+05</td>\n",
       "      <td>2988.706919</td>\n",
       "      <td>265.785843</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>889.185616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.112916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.465683</td>\n",
       "      <td>5143.795710</td>\n",
       "      <td>227.713325</td>\n",
       "      <td>1.136714</td>\n",
       "      <td>29.875625</td>\n",
       "      <td>195.927034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153926</th>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>2015-01-21 14:16:05</td>\n",
       "      <td>928.088027</td>\n",
       "      <td>19.677228</td>\n",
       "      <td>7.685628e+05</td>\n",
       "      <td>2988.706919</td>\n",
       "      <td>265.785843</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>889.185616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.112916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.465683</td>\n",
       "      <td>5143.795710</td>\n",
       "      <td>227.713325</td>\n",
       "      <td>1.136714</td>\n",
       "      <td>29.875625</td>\n",
       "      <td>195.927034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153927</th>\n",
       "      <td>NaN</td>\n",
       "      <td>112</td>\n",
       "      <td>2015-01-21 14:16:52</td>\n",
       "      <td>928.088027</td>\n",
       "      <td>19.677228</td>\n",
       "      <td>7.685628e+05</td>\n",
       "      <td>2988.706919</td>\n",
       "      <td>265.785843</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>889.185616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.112916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.465683</td>\n",
       "      <td>5143.795710</td>\n",
       "      <td>227.713325</td>\n",
       "      <td>1.136714</td>\n",
       "      <td>29.875625</td>\n",
       "      <td>195.927034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153928</th>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>2015-01-21 14:17:18</td>\n",
       "      <td>928.088027</td>\n",
       "      <td>19.677228</td>\n",
       "      <td>7.685628e+05</td>\n",
       "      <td>2988.706919</td>\n",
       "      <td>265.785843</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>889.185616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.112916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.465683</td>\n",
       "      <td>5143.795710</td>\n",
       "      <td>227.713325</td>\n",
       "      <td>1.136714</td>\n",
       "      <td>29.875625</td>\n",
       "      <td>195.927034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153929 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 device  score                time  avg_score_per_session  \\\n",
       "0                     0     45 2015-04-11 11:52:38             205.500000   \n",
       "1                     0    115 2015-04-11 11:53:33             205.500000   \n",
       "2                     0     14 2015-04-11 11:54:32             205.500000   \n",
       "3                     0    237 2016-02-11 07:56:21             205.500000   \n",
       "4       000000000000000      1 2015-01-23 02:04:44            1518.000000   \n",
       "...                 ...    ...                 ...                    ...   \n",
       "153924              NaN    847 2015-01-21 14:14:14             928.088027   \n",
       "153925              NaN    374 2015-01-21 14:15:37             928.088027   \n",
       "153926              NaN     35 2015-01-21 14:16:05             928.088027   \n",
       "153927              NaN    112 2015-01-21 14:16:52             928.088027   \n",
       "153928              NaN     31 2015-01-21 14:17:18             928.088027   \n",
       "\n",
       "        total_sessions  session_frequency  max_score_per_session  \\\n",
       "0             2.000000       2.642411e+07             237.000000   \n",
       "1             2.000000       2.642411e+07             237.000000   \n",
       "2             2.000000       2.642411e+07             237.000000   \n",
       "3             2.000000       2.642411e+07             237.000000   \n",
       "4             8.000000       4.558758e+06            5847.000000   \n",
       "...                ...                ...                    ...   \n",
       "153924       19.677228       7.685628e+05            2988.706919   \n",
       "153925       19.677228       7.685628e+05            2988.706919   \n",
       "153926       19.677228       7.685628e+05            2988.706919   \n",
       "153927       19.677228       7.685628e+05            2988.706919   \n",
       "153928       19.677228       7.685628e+05            2988.706919   \n",
       "\n",
       "        recency_of_last_session       last_activity  churn  ...    max_score  \\\n",
       "0                    103.000000 2016-02-11 07:56:21      1  ...   237.000000   \n",
       "1                    103.000000 2016-02-11 07:56:21      1  ...   237.000000   \n",
       "2                    103.000000 2016-02-11 07:56:21      1  ...   237.000000   \n",
       "3                    103.000000 2016-02-11 07:56:21      1  ...   237.000000   \n",
       "4                    118.000000 2016-01-27 10:20:57      1  ...  2317.000000   \n",
       "...                         ...                 ...    ...  ...          ...   \n",
       "153924               265.785843                 NaT      0  ...   889.185616   \n",
       "153925               265.785843                 NaT      0  ...   889.185616   \n",
       "153926               265.785843                 NaT      0  ...   889.185616   \n",
       "153927               265.785843                 NaT      0  ...   889.185616   \n",
       "153928               265.785843                 NaT      0  ...   889.185616   \n",
       "\n",
       "         std_score  days_since_first  days_between_sessions  session_count  \\\n",
       "0        98.969271          0.000000                    0.0       4.000000   \n",
       "1        98.969271          0.000000                    0.0       4.000000   \n",
       "2        98.969271          0.000000                    0.0       4.000000   \n",
       "3        98.969271        305.000000                  305.0       4.000000   \n",
       "4       398.282132          0.000000                    0.0      40.000000   \n",
       "...            ...               ...                    ...            ...   \n",
       "153924    0.000000         20.112916                    0.0     126.465683   \n",
       "153925    0.000000         20.112916                    0.0     126.465683   \n",
       "153926    0.000000         20.112916                    0.0     126.465683   \n",
       "153927    0.000000         20.112916                    0.0     126.465683   \n",
       "153928    0.000000         20.112916                    0.0     126.465683   \n",
       "\n",
       "        score_density  last_session_score  last_score_ratio  \\\n",
       "0          411.000000          237.000000          2.284337   \n",
       "1          411.000000          237.000000          2.284337   \n",
       "2          411.000000          237.000000          2.284337   \n",
       "3            1.343137          237.000000          2.284337   \n",
       "4        12144.000000          115.000000          0.377544   \n",
       "...               ...                 ...               ...   \n",
       "153924    5143.795710          227.713325          1.136714   \n",
       "153925    5143.795710          227.713325          1.136714   \n",
       "153926    5143.795710          227.713325          1.136714   \n",
       "153927    5143.795710          227.713325          1.136714   \n",
       "153928    5143.795710          227.713325          1.136714   \n",
       "\n",
       "        activity_intensity  combined_score  \n",
       "0                 4.000000      102.750000  \n",
       "1                 4.000000      102.750000  \n",
       "2                 4.000000      102.750000  \n",
       "3                 0.013072      102.750000  \n",
       "4                40.000000      303.600000  \n",
       "...                    ...             ...  \n",
       "153924           29.875625      195.927034  \n",
       "153925           29.875625      195.927034  \n",
       "153926           29.875625      195.927034  \n",
       "153927           29.875625      195.927034  \n",
       "153928           29.875625      195.927034  \n",
       "\n",
       "[153929 rows x 22 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare features and target variable\n",
    "# features = ['avg_score_per_session', 'total_sessions', 'session_frequency', \n",
    "#             'max_score_per_session', 'recency_of_last_session']\n",
    "# features = data.drop(columns=['churn', 'recency_of_last_session', 'device', 'last_activity',\n",
    "#                               'time'])\n",
    "features = [\n",
    "    'score',\n",
    "    'session_frequency',\n",
    "    'days_since_first',\n",
    "    'days_between_sessions',\n",
    "    'activity_intensity',\n",
    "    'total_sessions',\n",
    "    'score_density',\n",
    "    'std_score'\n",
    "]\n",
    "\n",
    "X = data[features]\n",
    "\n",
    "y = data['churn']\n",
    "\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of churners before SMOTE: 97.26%\n",
      "Percentage of churners after SMOTE: 50.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print percentage of churners in the training set before SMOTE\n",
    "churners_before = y_train.sum() / len(y_train) * 100\n",
    "print(f\"Percentage of churners before SMOTE: {churners_before:.2f}%\")\n",
    "\n",
    "# Address class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print percentage of churners in the training set after SMOTE\n",
    "churners_after = y_train_resampled.sum() / len(y_train_resampled) * 100\n",
    "print(f\"Percentage of churners after SMOTE: {churners_after:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Feature       VIF\n",
      "0                  const  2.279549\n",
      "1                  score  1.389576\n",
      "2      session_frequency  1.175047\n",
      "3       days_since_first  1.292667\n",
      "4  days_between_sessions  1.161193\n",
      "5     activity_intensity  2.406849\n",
      "6         total_sessions  1.232173\n",
      "7          score_density  2.418516\n",
      "8              std_score  1.467700\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# Add a constant column to the feature set for VIF calculation\n",
    "X_train_const = add_constant(X_train_resampled)\n",
    "\n",
    "# Calculate VIF for each feature, including the constant\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X_train_const.columns  # Use columns from X_train_const to match the VIF calculation\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_train_const.values, i) for i in range(X_train_const.shape[1])]\n",
    "\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppping features with high VIF score\n",
    "# X_train_reduced = X_train.drop(columns=['max_score', 'max_score_per_session', 'total_score', 'session_count'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Accuracy Scores: [0.61214753 0.61166114 0.61387981 0.61218599 0.61120786]\n",
      "Mean Cross-Validation Accuracy: 0.6122164651691385\n",
      "\n",
      "Accuracy Score on Test Set: 0.8059074471079928\n",
      "\n",
      "Confusion Matrix on Test Set:\n",
      " [[  514   754]\n",
      " [ 8209 36702]]\n",
      "\n",
      "Classification Report on Test Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.41      0.10      1268\n",
      "           1       0.98      0.82      0.89     44911\n",
      "\n",
      "    accuracy                           0.81     46179\n",
      "   macro avg       0.52      0.61      0.50     46179\n",
      "weighted avg       0.95      0.81      0.87     46179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train a logistic regression model with 5-fold cross-validation\n",
    "model = LogisticRegression(penalty='l2', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "# Perform Stratified 5-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, X_train_scaled, y_train_resampled, cv=skf, scoring='accuracy')\n",
    "\n",
    "# Print Cross-Validation Results\n",
    "print(\"\\nCross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Cross-Validation Accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Train the model on the full resampled training data\n",
    "model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"\\nAccuracy Score on Test Set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix on Test Set:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report on Test Set:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Random Forest Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Random Forest Best CV Accuracy: 0.989507898950662\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Random Forest: Define parameter grid\n",
    "# rf_params = {\n",
    "#     \"n_estimators\": [100, 200, 300],\n",
    "#     \"max_depth\": [None, 10, 20, 30],\n",
    "#     \"min_samples_split\": [2, 5, 10],\n",
    "#     \"min_samples_leaf\": [1, 2, 4]\n",
    "# }\n",
    "\n",
    "# Random Forest Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "rf_params = {'max_depth': [None], 'min_samples_leaf': [1], 'min_samples_split': [2], 'n_estimators': [100]}\n",
    "\n",
    "# Random Forest: Initialize model and grid search\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=rf_params,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit Random Forest with grid search\n",
    "rf_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best parameters and accuracy for Random Forest\n",
    "rf_best_params = rf_grid_search.best_params_\n",
    "rf_best_score = rf_grid_search.best_score_\n",
    "print(\"Random Forest Best Parameters:\", rf_best_params)\n",
    "print(\"Random Forest Best CV Accuracy:\", rf_best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 1089   179]\n",
      " [  224 44687]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Get the best estimator from grid search\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "\n",
    "# Step 2: Make predictions using the test data (or validation set)\n",
    "y_pred = best_rf_model.predict(X_test)  # Assuming X_test and y_test are your test set\n",
    "\n",
    "# Step 3: Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Step 4: Plot the confusion matrix for better visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=best_rf_model.classes_, yticklabels=best_rf_model.classes_)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Optionally, print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [09:05:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 25\u001b[0m\n\u001b[1;32m     15\u001b[0m xgb_grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     16\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mxgb_model,\n\u001b[1;32m     17\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mxgb_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Fit XGBoost with grid search\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mxgb_grid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Best parameters and accuracy for XGBoost\u001b[39;00m\n\u001b[1;32m     28\u001b[0m xgb_best_params \u001b[38;5;241m=\u001b[39m xgb_grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# XGBoost: Define parameter grid\n",
    "xgb_params = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"max_depth\": [2, 3, 4, 6],\n",
    "    # \"subsample\": [0.8, 1.0],\n",
    "    # \"colsample_bytree\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# XGBoost: Initialize model and grid search\n",
    "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=xgb_params,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit XGBoost with grid search\n",
    "xgb_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best parameters and accuracy for XGBoost\n",
    "xgb_best_params = xgb_grid_search.best_params_\n",
    "xgb_best_score = xgb_grid_search.best_score_\n",
    "print(\"XGBoost Best Parameters:\", xgb_best_params)\n",
    "print(\"XGBoost Best CV Accuracy:\", xgb_best_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
